{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf20b83c-d4fd-41e1-9021-e3908d1d48a9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; border: 1px solid gray; padding: 3px\">\n",
    "    This notebook consists of 2 agentic workflows:\n",
    "        <h3>Data Generation Workflow</h3>\n",
    "        <li><b>Data Augmentation</b>: Augments the provided image dataset.</li>\n",
    "        <h3>Validation Workflow</h3>\n",
    "        <li><b>Image Validator</b>: Identifies whether a valid driver's license exists in the given image.</li>\n",
    "        <li><b>Data Extractor</b>: Extracts relevant metadata from the image.</li>\n",
    "        <li><b>Application Validator</b>: Given the extracted metadata associated with the application, uses a set of predefined rules to validate the driver's license application.</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20a007-63ad-4192-980a-5ebb5630e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Imports\n",
    "##############################################################################\n",
    "# import pysqlite3 as sqlite3\n",
    "# import sys\n",
    "# sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, List, Optional, Literal\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph.message import add_messages\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from flow_extensions import CustomLLMMultimodalBlock, CustomDeleteColumnsBlock\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "import mimetypes\n",
    "import base64\n",
    "from urllib.parse import urlparse\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "load_dotenv()\n",
    "import traceback\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field, TypeAdapter\n",
    "from more_itertools import chunked\n",
    "import utils\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sdg_hub.core.flow import FlowRegistry, Flow\n",
    "import pandas as pd\n",
    "from typing import Any, Optional\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ff1fc-e78a-42b4-8454-5f0f9613cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# State Definitions\n",
    "##############################################################################\n",
    "\n",
    "class LicenseState(TypedDict):\n",
    "    \"\"\"Enhanced state definition\"\"\"\n",
    "\n",
    "    github_repo: str\n",
    "\n",
    "    github_subfolder: str\n",
    "\n",
    "    vision_model: str\n",
    "\n",
    "    analytics_data: pd.DataFrame\n",
    "\n",
    "    messages: Annotated[List[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ba1dc-c9f9-4869-8ea0-1098cbfe52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Structured Output\n",
    "##############################################################################\n",
    "\n",
    "class DriversLicenseField(BaseModel):\n",
    "    \n",
    "    value: str = Field(\"\", description=\"Name of field\")\n",
    "    \n",
    "    missing_error_reason: str = Field(\"\", description=\"Reason for missing field\")\n",
    "\n",
    "    is_valid: Optional[bool] = Field(None, description=\"Indicates whether the license is valid.\")\n",
    "    \n",
    "    application_value: str = Field(\"\", description=\"Value of the corresponding field in the application\")\n",
    "    \n",
    "    invalid_error_reason: str = Field(\"\", description=\"Reason for invalid field\")\n",
    "\n",
    "    \n",
    "\n",
    "class DriversLicenseMetadata(BaseModel):\n",
    "\n",
    "    application_id: str = Field(\"\", description=\"Unique identifier\")\n",
    "\n",
    "    model: str = Field(\"\", description=\"Name of LLM used to generate metadata\")\n",
    "    \n",
    "    name: DriversLicenseField = Field(description=\"Name of driver's license owner\")\n",
    "    \n",
    "    date_of_birth: DriversLicenseField = Field(description=\"Date of birth of driver's license owner\")\n",
    "    \n",
    "    expiration_date: DriversLicenseField = Field(description=\"Expiration date of driver's license\")\n",
    "    \n",
    "    state_issued: DriversLicenseField = Field(description=\"State where the license was issued\")\n",
    "    \n",
    "    issuance_date: DriversLicenseField = Field(description=\"Date when the license was issued\")\n",
    "\n",
    "    photo_orientation: DriversLicenseField = Field(\"\", description=\"The skew of the license in the photo\")\n",
    "\n",
    "class LicenseApplication(BaseModel):\n",
    "\n",
    "    application_id: str = Field(description=\"Unique identifier\")\n",
    "\n",
    "    image_path: str = Field(description=\"Image path\")\n",
    "\n",
    "    application_data: dict = Field(description=\"Submitted application data\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eba590-6bcb-46df-9928-91d27ebff636",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Tools\n",
    "##############################################################################\n",
    "\n",
    "def image_to_base64(image_path, encode_image_bytes=False):\n",
    "    \"\"\"Transforms image at provided local path or URL into base64-encoded representation.\"\"\"\n",
    "    \n",
    "    def is_valid_http_url(input_path):\n",
    "        \"\"\"Returns whether or not the input is a valid URL.\"\"\"\n",
    "    \n",
    "        parsed_url = urlparse(input_path)\n",
    "    \n",
    "        is_http_url = all([parsed_url.scheme in ('http', 'https'), parsed_url.netloc])\n",
    "    \n",
    "        return is_http_url\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "    \n",
    "        mime_type, _ = mimetypes.guess_type(image_path)\n",
    "    \n",
    "        if \"image\" in mime_type:\n",
    "    \n",
    "            if encode_image_bytes:\n",
    "    \n",
    "                if is_valid_http_url(image_path):\n",
    "        \n",
    "                    response = requests.get(image_path)\n",
    "    \n",
    "                    response.raise_for_status()\n",
    "    \n",
    "                    stream_to_read = response.content\n",
    "    \n",
    "                else:\n",
    "                    \n",
    "                    with open(image_path, \"rb\") as image_file:\n",
    "                        \n",
    "                        stream_to_read = image_file.read()\n",
    "    \n",
    "                img = base64.b64encode(stream_to_read).decode(\"utf-8\")\n",
    "        \n",
    "                return f\"data:{mime_type};base64,{img}\"\n",
    "    \n",
    "            else:\n",
    "    \n",
    "                return image_path\n",
    "                \n",
    "    \n",
    "        else:\n",
    "    \n",
    "            raise Exception(f\"Mime type {mime_type} not supported\")\n",
    "        \n",
    "        processing_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        print(f\"Image loaded: time: {processing_time:.2f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        \n",
    "        error_msg = f\"Image loading error: {str(e)}\"\n",
    "    \n",
    "        print(f\"- {error_msg}\")\n",
    "\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0a61b-a335-4459-a7cd-75e195131b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Nodes\n",
    "##############################################################################\n",
    "\n",
    "def load_and_convert_from_github(state: LicenseState) -> LicenseState:\n",
    "    \"\"\"Converts the images in the provided github repo folder into a paired representation of images and their applications.\"\"\"\n",
    "    print(\"✓ STEP 1: Conversion of Github Repositories into a paired image-to-application representation\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    ############################################################################################################################\n",
    "    # Group the files by ID\n",
    "    ############################################################################################################################\n",
    "    applications = utils.group_files_by_id(state[\"github_repo\"], state[\"github_subfolder\"])\n",
    "\n",
    "    ############################################################################################################################\n",
    "    # Use static rules to transform the data into specifically identified submitted fields\n",
    "    ############################################################################################################################\n",
    "    submitted_fields = utils.convert_to_submitted_fields(applications, \"patterns.json\")\n",
    "\n",
    "    ############################################################################################################################\n",
    "    # Represent the files as a dataframe\n",
    "    ############################################################################################################################\n",
    "    df = pd.DataFrame(submitted_fields)\n",
    "    \n",
    "    return {\n",
    "        \"analytics_data\" : df,\n",
    "        \"messages\": [AIMessage(content=\"License applications retrieved from github and converted.\")]\n",
    "    }\n",
    "\n",
    "def get_extracted_data(state: LicenseState) -> LicenseState:\n",
    "    \"\"\"Extracts the drivers license data from the images in the provided git repository.\"\"\"\n",
    "\n",
    "    print(\"✓ STEP 2: AI-Powered Data Extraction\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "    ############################################################################################################################\n",
    "    # Retrieve the application data\n",
    "    ############################################################################################################################\n",
    "    df = state[\"analytics_data\"]\n",
    "\n",
    "    ############################################################################################################################\n",
    "    # Add the current model\n",
    "    ############################################################################################################################\n",
    "    model_prefix = state[\"vision_model\"]\n",
    "    \n",
    "    df[\"model_name\"] = os.getenv(f\"{model_prefix}_LLM_NAME\")\n",
    "\n",
    "    ############################################################################################################################\n",
    "    # Build a dataset for sdg_hub\n",
    "    ############################################################################################################################\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "\n",
    "    ############################################################################################################################\n",
    "    # Run sdg_hub\n",
    "    ############################################################################################################################\n",
    "    flow_path = \"flows/drivers_license_validation/flow.yaml\"\n",
    "    \n",
    "    flow = Flow.from_yaml(flow_path)\n",
    "    \n",
    "    flow.set_model_config(\n",
    "        model=os.getenv(f\"{model_prefix}_LLM_NAME\"),\n",
    "        api_base=os.getenv(f\"{model_prefix}_LLM_BASE\"),\n",
    "        api_key=os.getenv(f\"{model_prefix}_LLM_KEY\"),\n",
    "        temperature=0,\n",
    "        \n",
    "        max_tokens = 8192,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        top_k=1,\n",
    "    )\n",
    "\n",
    "    converted_dataset = flow.generate(dataset, max_concurrency=10)\n",
    "    \n",
    "    converted_df = converted_dataset.to_pandas()\n",
    "\n",
    "    state[\"analytics_data\"] = converted_df\n",
    "\n",
    "    return {\n",
    "        \"analytics_data\" : converted_df,\n",
    "        \"messages\": [AIMessage(content=\"License data extracted.\")]\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_extracted_data(state: LicenseState) -> LicenseState:\n",
    "    \"\"\"Node: Validate extracted data\"\"\"\n",
    "    print(\"✓ STEP 3: Data Validation\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def compile_final_result(state: LicenseState) -> LicenseState:\n",
    "    \"\"\"Node: Generate reports\"\"\"\n",
    "    print(\"✓ STEP 4: Compiling Final Results\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # TODO\n",
    "\n",
    "    ############################################################################################################################\n",
    "    # Serialize the application data to a file\n",
    "    ############################################################################################################################]\n",
    "    \n",
    "    return {\"messages\": [HumanMessage(content=\"DONE\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af32f97-bf74-444a-b442-f6d381d1d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Graph\n",
    "##############################################################################\n",
    "def create_license_extraction_graph():\n",
    "    \"\"\"Create the LangGraph workflow\"\"\"\n",
    "    workflow = StateGraph(LicenseState)\n",
    "    \n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"load_from_github\", load_and_convert_from_github)\n",
    "    \n",
    "    workflow.add_node(\"extract_data\", get_extracted_data)\n",
    "    \n",
    "    workflow.add_node(\"validate_data\", validate_extracted_data)\n",
    "    \n",
    "    workflow.add_node(\"compile_result\", compile_final_result)\n",
    "    \n",
    "    # Define edges\n",
    "    workflow.add_edge(START, \"load_from_github\")\n",
    "    \n",
    "    workflow.add_edge(\"load_from_github\", \"extract_data\")\n",
    "    \n",
    "    workflow.add_edge(\"extract_data\", \"validate_data\")\n",
    "    \n",
    "    workflow.add_edge(\"validate_data\", \"compile_result\")\n",
    "    \n",
    "    workflow.add_edge(\"compile_result\", END)\n",
    "    \n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c0788-d85a-437b-a300-b6e3e7054eae",
   "metadata": {},
   "source": [
    "### Execute Code Translation Flow\n",
    "Execute the flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7486ea-5f5d-453c-9c50-fb19214b2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Execute the Flow\n",
    "##############################################################################\n",
    "\n",
    "def extract_license_info(github_repo: str, github_subfolder: str, vision_model: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main extraction function\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    print(f\"Started pipeline: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    initial_state = {\n",
    "        \"github_repo\": github_repo,\n",
    "\n",
    "        \"github_subfolder\": github_subfolder,\n",
    "\n",
    "        \"vision_model\": model_prefix,\n",
    "\n",
    "        \"messages\": [HumanMessage(f\"Validate driver's license data for {model_prefix} model...\")]\n",
    "        \n",
    "    }\n",
    "\n",
    "    graph = create_license_extraction_graph()\n",
    "            \n",
    "    # final_state = app.invoke(initial_state)\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": 42, \"recursion_limit\": 5}}\n",
    "\n",
    "    stream = graph.stream(initial_state, config, stream_mode=\"values\")\n",
    "\n",
    "    for event in stream:\n",
    "        last_message = event['messages'][-1]\n",
    "        \n",
    "        last_message.pretty_print()\n",
    "\n",
    "        if \"DONE\" in last_message.content:\n",
    "\n",
    "            return event[\"analytics_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a9bc0-df77-428e-8e56-603be498ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_models = [\"LLAMASCOUT4\", \"GEMMA27B\", \"GEMMA12B\"]\n",
    "\n",
    "target_dir = \"reports\"\n",
    "    \n",
    "datasets = []\n",
    "\n",
    "##############################################################################\n",
    "# Generate Extracted Data and Evaluations\n",
    "##############################################################################\n",
    "for model_prefix in vision_models:\n",
    "\n",
    "    try:\n",
    "\n",
    "        df = extract_license_info(\"https://github.com/agapebondservant/dla_poc\", \"notebooks/data2\", model_prefix)\n",
    "\n",
    "        datasets.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"Error occurred while processing with model {model_prefix}: e\")\n",
    "\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3fbaa-7e74-4e4c-a384-f77b36510797",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Generate Reports\n",
    "##############################################################################\n",
    "combined_df = pd.concat(datasets)\n",
    "# transformed_df = utils.data_report_prep(combined_df)\n",
    "utils.generate_csv_report(combined_df, target_dir)\n",
    "utils.generate_jsonl_report(combined_df, target_dir)\n",
    "# transformed_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
